<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yonggen Ling - Robotics Researcher</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Noto+Sans+SC:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #3b82f6;
            --primary-dark: #2563eb;
            --text-primary: #1f2937;
            --text-secondary: #4b5563;
            --text-muted: #6b7280;
            --bg-primary: #ffffff;
            --bg-secondary: #f8fafc;
            --bg-accent: #eff6ff;
            --border-color: #e5e7eb;
            --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);
            --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
            --shadow-lg: 0 10px 25px -5px rgb(0 0 0 / 0.15), 0 8px 10px -6px rgb(0 0 0 / 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', 'Noto Sans SC', -apple-system, BlinkMacSystemFont, sans-serif;
            line-height: 1.7;
            color: var(--text-primary);
            background: linear-gradient(145deg, #e8ecef 0%, #d5dde3 35%, #c9d4dc 65%, #bcc8d1 100%);
            min-height: 100vh;
            padding: 40px 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
        }

        /* Header Card */
        .header-card {
            background: var(--bg-primary);
            border-radius: 20px;
            box-shadow: var(--shadow-lg);
            padding: 40px;
            margin-bottom: 30px;
            display: flex;
            gap: 40px;
            align-items: flex-start;
        }

        .photo-wrapper {
            flex-shrink: 0;
        }

        .photo-wrapper img {
            width: 200px;
            height: 227px;
            object-fit: cover;
            border-radius: 16px;
            box-shadow: var(--shadow-md);
            transition: transform 0.3s ease;
        }

        .photo-wrapper img:hover {
            transform: scale(1.02);
        }

        .header-info {
            flex: 1;
        }

        .name {
            font-size: 2.5rem;
            font-weight: 700;
            color: var(--text-primary);
            margin-bottom: 4px;
            letter-spacing: -0.5px;
        }

        .name-cn {
            font-size: 1.5rem;
            color: var(--text-muted);
            font-weight: 500;
            margin-bottom: 12px;
        }

        .title-badge {
            display: inline-block;
            background: var(--bg-accent);
            color: var(--primary-color);
            padding: 6px 16px;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 600;
            margin-bottom: 16px;
        }

        .affiliation {
            color: var(--text-secondary);
            font-size: 0.95rem;
            margin-bottom: 12px;
            line-height: 1.6;
        }

        .affiliation a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        .affiliation a:hover {
            color: var(--primary-dark);
            text-decoration: underline;
        }

        .email {
            font-size: 0.95rem;
            color: var(--text-secondary);
        }

        .email strong {
            color: var(--text-primary);
        }

        /* Section Cards */
        .section-card {
            background: var(--bg-primary);
            border-radius: 16px;
            box-shadow: var(--shadow-md);
            padding: 32px;
            margin-bottom: 24px;
        }

        .section-title {
            font-size: 1.5rem;
            font-weight: 700;
            color: var(--text-primary);
            margin-bottom: 20px;
            padding-bottom: 12px;
            border-bottom: 3px solid var(--primary-color);
            display: inline-block;
        }

        /* Biography */
        .biography {
            color: var(--text-secondary);
            text-align: justify;
            line-height: 1.8;
        }

        .biography a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
        }

        .biography a:hover {
            text-decoration: underline;
        }

        /* Highlight Box */
        .highlight-box {
            background: linear-gradient(135deg, var(--bg-accent) 0%, #dbeafe 100%);
            border-left: 4px solid var(--primary-color);
            padding: 20px 24px;
            border-radius: 0 12px 12px 0;
            margin-top: 24px;
        }

        .highlight-box p {
            color: var(--text-primary);
            font-weight: 500;
            line-height: 1.7;
        }

        .highlight-box a {
            color: var(--primary-color);
            font-weight: 600;
        }

        /* Publications */
        .pub-note {
            color: var(--text-muted);
            font-size: 0.9rem;
            margin-bottom: 20px;
        }

        .publication-list {
            list-style: none;
            counter-reset: pub-counter;
        }

        .publication-list > li {
            counter-increment: pub-counter;
            position: relative;
            padding: 20px;
            padding-left: 50px;
            margin-bottom: 16px;
            background: var(--bg-secondary);
            border-radius: 12px;
            transition: box-shadow 0.2s, transform 0.2s;
        }

        .publication-list > li:hover {
            box-shadow: var(--shadow-sm);
            transform: translateX(4px);
        }

        .publication-list > li::before {
            content: counter(pub-counter);
            position: absolute;
            left: 16px;
            top: 20px;
            width: 24px;
            height: 24px;
            background: var(--primary-color);
            color: white;
            border-radius: 50%;
            font-size: 0.75rem;
            font-weight: 600;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .pub-authors {
            color: var(--text-secondary);
            font-size: 0.9rem;
            margin-bottom: 6px;
        }

        .pub-authors strong {
            color: var(--primary-color);
        }

        .pub-title {
            font-weight: 600;
            color: var(--text-primary);
            margin-bottom: 6px;
            font-size: 1rem;
        }

        .pub-venue {
            color: var(--text-muted);
            font-size: 0.9rem;
        }

        .pub-venue em {
            font-style: normal;
        }

        .pub-venue strong {
            color: var(--primary-dark);
            background: var(--bg-accent);
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 0.8rem;
        }

        .pub-links {
            margin-top: 10px;
        }

        .pub-links a {
            display: inline-block;
            color: var(--primary-color);
            text-decoration: none;
            font-size: 0.85rem;
            font-weight: 500;
            margin-right: 12px;
            padding: 4px 10px;
            background: var(--bg-accent);
            border-radius: 6px;
            transition: background 0.2s;
        }

        .pub-links a:hover {
            background: #dbeafe;
        }

        /* Experience List */
        .experience-list {
            list-style: none;
        }

        .experience-item {
            padding: 16px 20px;
            background: var(--bg-secondary);
            border-radius: 12px;
            margin-bottom: 12px;
            border-left: 4px solid var(--primary-color);
        }

        .experience-item .exp-title {
            font-weight: 600;
            color: var(--text-primary);
            margin-bottom: 4px;
        }

        .experience-item .exp-detail {
            color: var(--text-muted);
            font-size: 0.9rem;
        }

        /* Awards */
        .awards-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
            gap: 12px;
        }

        .award-item {
            padding: 16px;
            background: var(--bg-secondary);
            border-radius: 10px;
            border-left: 3px solid var(--primary-color);
        }

        .award-item .award-name {
            font-weight: 600;
            color: var(--text-primary);
            font-size: 0.95rem;
            margin-bottom: 4px;
        }

        .award-item .award-org {
            color: var(--text-muted);
            font-size: 0.85rem;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            body {
                padding: 20px 12px;
            }

            .header-card {
                flex-direction: column;
                align-items: center;
                text-align: center;
                padding: 28px 20px;
                gap: 24px;
            }

            .photo-wrapper img {
                width: 160px;
                height: 181px;
            }

            .name {
                font-size: 1.8rem;
            }

            .name-cn {
                font-size: 1.2rem;
            }

            .section-card {
                padding: 24px 20px;
            }

            .section-title {
                font-size: 1.3rem;
            }

            .publication-list > li {
                padding-left: 44px;
            }

            .awards-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Header Section -->
        <header class="header-card">
            <div class="photo-wrapper">
                <a href="https://sites.google.com/site/ygling2008/home/photo.png?attredirects=0">
                    <img src="https://ygling2008.github.io/photo.png" alt="Photo of Yonggen Ling">
                </a>
            </div>
            <div class="header-info">
                <h1 class="name">Yonggen Ling</h1>
                <div class="name-cn">凌永根</div>
                <span class="title-badge">Ph.D. 2017</span>
                <p class="affiliation">
                    <a href="https://roboticsx.tencent.com/">Tencent Robotics X</a>
                </p>
                <p class="email"><strong>Email:</strong> ylingaa AT connect.ust.hk</p>
            </div>
        </header>

        <!-- Biography Section -->
        <section class="section-card">
            <h2 class="section-title">Biography</h2>
            <div class="biography">
<p>I earned my Ph.D. from the Robotics Institute at <a href="https://hkust.edu.hk/"><strong>HKUST</strong></a> in 2017. My journey in tech started with competitive programming — as an <a href="https://icpc.global/">ACM-ICPC</a> participant during my undergraduate years, I developed strong problem-solving skills that became the backbone of my research career.</p>
<p style="margin-top: 12px;">My first research experience was at the <a href="https://www.mtrec.ust.hk/">Multimedia Technology Research Center (<strong>MTrec</strong>)</a> under Prof. Oscar C. Au (<strong>IEEE Fellow</strong>), where I explored image processing, video coding, and signal processing. In late 2013, I joined <a href="https://www.dji.com/">DJI</a> as an intern and built vision systems for drones — an experience that sparked my passion for computer vision and robotics.</p>
                <p style="margin-top: 12px;">This led me to <a href="http://uav.ust.hk/">Prof. Shaojie Shen's UAV group</a>, where I dove deep into visual odometry, 3D mapping, SLAM, and autonomous navigation — the core technologies that enable robots to see, understand, and move through the world.</p>
            </div>
            <div class="highlight-box">
                <p>I am currently the Team Leader of the Multimodal Perception Group in the <a href="https://roboticsx.tencent.com/">Robotics X Lab</a> at Tencent. A few full-time/intern positions are available for talented Ph.D. and Master students. Please contact me via my email if you are interested and self-motivated to do cutting-edge work.</p>
            </div>
        </section>

        <!-- Publications Section -->
        <section class="section-card">
            <h2 class="section-title">Selected Publications</h2>
            <p class="pub-note">(*equal contribution, &#9993; corresponding author)</p>
            <ol class="publication-list">
                <li>
                    <div class="pub-authors">Kehan Chen, Dong An, Yan Huang, Rongtao Xu, Yifei Su, <strong>Yonggen Ling</strong>, Ian Reid, and Liang Wang</div>
                    <div class="pub-title">Shot Vision-Language Navigation in Continuous Environments</div>
                    <div class="pub-venue"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> <strong>TPAMI</strong>, 2025</div>
                </li>
                <li>
                    <div class="pub-authors">Junning Qiu, Minglei Lu, Fei Wang, Yu Guo, and <strong>Yonggen Ling</strong>&#9993;</div>
                    <div class="pub-title">Leveraging Global Stereo Consistency for Category-Level Shape and 6D Pose Estimation from Stereo Images</div>
                    <div class="pub-venue">in <em>Computer Vision and Pattern Recognition</em> <strong>CVPR</strong>, 2025</div>
                </li>
                <li>
                    <div class="pub-authors">Yifei Su, Dong An, Kehan Chen, Weichen Yu, Baiyang Ning, <strong>Yonggen Ling</strong>, Yan Huang, Liang Wang</div>
                    <div class="pub-title">Learning Fine-Grained Alignment for Aerial Vision-Dialog Navigation</div>
                    <div class="pub-venue">in <em>AAAI Conference on Artificial Intelligence</em> <strong>AAAI</strong>, 2025</div>
                </li>
                <li>
                    <div class="pub-authors">Chuanrui Zhang*, <strong>Yonggen Ling</strong>*&#9993;, Minglei Lu, Minghan Qin and Haoqian Wang</div>
                    <div class="pub-title">Category-level Object Detection, Pose Estimation and Reconstruction from Stereo Images</div>
                    <div class="pub-venue">in <em>European Conference on Computer Vision</em> <strong>ECCV</strong>, 2024</div>
                </li>
                <li>
                    <div class="pub-authors">Zhaoliang Wan, <strong>Yonggen Ling</strong>&#9993;, Senlin Yi, Lu Qi, Minglei Lu, Wangwei Lee, Sicheng Yang, Xiao Teng, Peng Lu, Xu Yang, Ming-Hsuan Yang, and Hui Cheng</div>
                    <div class="pub-title">VinT-6D: A Large-Scale Object-in-hand Dataset from Vision, Touch and Proprioception</div>
                    <div class="pub-venue">in <em>International Conference on Machine Learning</em> <strong>ICML</strong>, 2024</div>
                </li>
                <li>
                    <div class="pub-authors">Kaspar Althoefer*, <strong>Yonggen Ling</strong>*, Xinyuan Qian, Wang Wei Lee, Peng Qi and Wanlin Li</div>
                    <div class="pub-title">A Miniaturised Camera-based Multi-Modal Tactile Sensor</div>
                    <div class="pub-venue">in <em>IEEE International Conference on Robotics and Automation</em> <strong>ICRA</strong>, 2023</div>
                </li>
                <li>
                    <div class="pub-authors">Boxiang Zhang, Zunran Wang, <strong>Yonggen Ling</strong>, Yuanyuan Guan, Shenghao Zhang and Wenhui Li</div>
                    <div class="pub-title">Mx2M: Masked Cross-Modality Modeling in Domain Adaptation for 3D Semantic Segmentation</div>
                    <div class="pub-venue">in <em>AAAI Conference on Artificial Intelligence</em> <strong>AAAI</strong>, 2023</div>
                </li>
                <li>
                    <div class="pub-authors">Shifeng Lin, Zunran Wang, Shenghao Zhang, <strong>Yonggen Ling</strong>, Chenguang Yang</div>
                    <div class="pub-title">Deep Fusion for Multi-Modal 6D Pose Estimation</div>
                    <div class="pub-venue"><em>IEEE Transactions on Automation Science and Engineering</em> <strong>TASE</strong>, 2023</div>
                </li>
                <li>
                    <div class="pub-authors">Haoxian Zhang* and <strong>Yonggen Ling</strong>*&#9993;</div>
                    <div class="pub-title">HVC-Net: Unifying Homography, Visibility, and Confidence Learning for Planar Object Tracking</div>
                    <div class="pub-venue">in <em>European Conference on Computer Vision</em> <strong>ECCV</strong>, 2022</div>
                </li>
                <li>
                    <div class="pub-authors">Shifeng Lin, Zunran Wang, <strong>Yonggen Ling</strong>, Yidan Tao and Chenguang Yang</div>
                    <div class="pub-title">E2EK: End-to-End Regression Network Based on Keypoint for 6D Pose Estimation</div>
                    <div class="pub-venue"><em>IEEE Robotics and Automation Letters</em> <strong>RAL</strong>, 2022</div>
                    <div class="pub-links"><a href="https://ieeexplore.ieee.org/document/9772945">Paper</a></div>
                </li>
                <li>
                    <div class="pub-authors">Hanzhong Liu, Bidan Huang, Qiang Li, Yu Zheng, <strong>Yonggen Ling</strong>, Wang Wei Lee, Yi Liu, Ya-Yen Tsai and Chenguang Yang</div>
                    <div class="pub-title">Multi-Finger Tactile Servoing for Grasping Adjustment under Partial Observation</div>
                    <div class="pub-venue">in <em>IEEE/RSJ International Conference on Intelligent Robots and Systems</em> <strong>IROS</strong>, 2022</div>
                </li>
                <li>
                    <div class="pub-authors">Yajing Chen, Fanzi Wu, Zeyu Wang, Yibing Song, <strong>Yonggen Ling</strong> and Linchao Bao</div>
                    <div class="pub-title">Self-Supervised Learning of Detailed 3D Face Reconstruction</div>
                    <div class="pub-venue"><em>IEEE Transactions on Image Processing</em> <strong>TIP</strong>, 2020</div>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/1910.11791">Paper</a>
                        <a href="https://github.com/cyj907/unsupervised-detail-layer">Code</a>
                    </div>
                </li>
                <li>
                    <div class="pub-authors"><strong>Yonggen Ling</strong> and Shaojie Shen</div>
                    <div class="pub-title">Real-time Dense Mapping for Online Processing and Navigation</div>
                    <div class="pub-venue"><em>Journal of Field Robotics</em> <strong>JFR</strong>, 2019</div>
                    <div class="pub-links"><a href="https://ygling2008.github.io/papers/JFR2019.pdf">Paper</a></div>
                </li>
                <li>
                    <div class="pub-authors">Fanzi Wu, Linchao Bao, Yajing Chen, <strong>Yonggen Ling</strong>, Yibing Song, Songnan Li, King N. Ngan and Wei Liu</div>
                    <div class="pub-title">MVF-Net: Multi-View 3D Face Morphable Model Regression</div>
                    <div class="pub-venue">in <em>Computer Vision and Pattern Recognition</em> <strong>CVPR</strong>, 2019</div>
                    <div class="pub-links"><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_MVF-Net_Multi-View_3D_Face_Morphable_Model_Regression_CVPR_2019_paper.pdf">Paper</a></div>
                </li>
                <li>
                    <div class="pub-authors"><strong>Yonggen Ling</strong>, Linchao Bao, Zequn Jie, Fengming Zhu, Ziyang Li, Shanmin Tang, Yongsheng Liu, Wei Liu and Tong Zhang</div>
                    <div class="pub-title">Modeling Varying Camera-IMU Time Offset in Optimization-Based Visual-Inertial Odometry</div>
                    <div class="pub-venue">in <em>European Conference on Computer Vision</em> <strong>ECCV</strong>, 2018</div>
                    <div class="pub-links"><a href="https://ygling2008.github.io/papers/ECCV2018.pdf">Paper</a></div>
                </li>
                <li>
                    <div class="pub-authors"><strong>Yonggen Ling</strong>, Kaixuan Wang and Shaojie Shen</div>
                    <div class="pub-title">Probabilistic Dense Reconstruction from a Moving Camera</div>
                    <div class="pub-venue">in <em>IEEE/RSJ International Conference on Intelligent Robots and Systems</em> <strong>IROS</strong>, 2018</div>
                    <div class="pub-links"><a href="https://arxiv.org/abs/1903.10673">Paper</a></div>
                </li>
                <li>
                    <div class="pub-authors">Zequn Jie, Pengfei Wang, <strong>Yonggen Ling</strong>, Bo Zhao, Jiashi Feng and Wei Liu</div>
                    <div class="pub-title">Left-Right Comparative Recurrent Model for Stereo Matching</div>
                    <div class="pub-venue">in <em>IEEE International Conference on Computer Vision and Pattern Recognition</em> <strong>CVPR</strong>, 2018</div>
                    <div class="pub-links"><a href="https://arxiv.org/abs/1804.00796">Paper</a></div>
                </li>
                <li>
                    <div class="pub-authors"><strong>Yonggen Ling</strong> and Shaojie Shen</div>
                    <div class="pub-title">Building Maps for Autonomous Navigation Using Sparse Visual SLAM Features</div>
                    <div class="pub-venue">in <em>IEEE/RSJ International Conference on Intelligent Robots and Systems</em> <strong>IROS</strong>, 2017</div>
                    <div class="pub-links"><a href="https://ygling2008.github.io/papers/IROS2017.pdf">Paper</a></div>
                </li>
                <li>
                    <div class="pub-authors"><strong>Yonggen Ling</strong> and Shaojie Shen</div>
                    <div class="pub-title">High-Precision Online Markerless Stereo Extrinsic Calibration</div>
                    <div class="pub-venue">in <em>IEEE/RSJ International Conference on Intelligent Robots and Systems</em> <strong>IROS</strong>, 2016</div>
                    <div class="pub-links"><a href="https://arxiv.org/abs/1903.10705">Paper</a></div>
                </li>
                <li>
                    <div class="pub-authors"><strong>Yonggen Ling</strong>, Tianbo Liu and Shaojie Shen</div>
                    <div class="pub-title">Aggressive Quadrotor Flight Using Dense Visual-Inertial Fusion</div>
                    <div class="pub-venue">in <em>IEEE International Conference on Robotics and Automation</em> <strong>ICRA</strong>, 2016</div>
                    <div class="pub-links"><a href="https://ygling2008.github.io/papers/ICRA2016.pdf">Paper</a></div>
                </li>
            </ol>
        </section>

        <!-- Work Experience Section -->
        <section class="section-card">
            <h2 class="section-title">Work Experience</h2>
            <ul class="experience-list">
<li class="experience-item">
                    <div class="exp-title">Research Assistant, <a href="https://hkust.edu.hk/">HKUST</a></div>
                    <div class="exp-detail">Sep. 2016 - Aug. 2017</div>
                </li>
<li class="experience-item">
                    <div class="exp-title">Intern in Vision Lab, <a href="https://www.dji.com/">DJI</a> </div>
                    <div class="exp-detail">Jan. 2014 - Dec. 2014</div>
                </li>
<li class="experience-item">
                    <div class="exp-title">Intern in Multimedia Lab, <a href="https://www.siat.ac.cn/">Shenzhen Institute of Advanced Technology (SIAT)</a></div>
                    <div class="exp-detail">Feb. 2012 - Sep. 2012 · Mentors: Prof. Shifeng Chen &amp; Prof. Wei Zhang</div>
                </li>
            </ul>
        </section>

        <!-- Awards Section -->
        <section class="section-card">
            <h2 class="section-title">Scholarships &amp; Awards</h2>
            <div class="awards-grid">
<div class="award-item">
                    <div class="award-name">Research Travel Grant</div>
                    <div class="award-org"><a href="https://hkust.edu.hk/">HKUST</a>, 2014, 2015, 2016</div>
                </div>
<div class="award-item">
                    <div class="award-name">Postgraduate Scholarship</div>
                    <div class="award-org"><a href="https://hkust.edu.hk/">HKUST</a>, Sep. 2012 - Aug. 2016</div>
                </div>
                <div class="award-item">
                    <div class="award-name">National Scholarship</div>
                    <div class="award-org">China, 2009, 2010, 2011</div>
                </div>
                <div class="award-item">
<div class="award-name">Google Excellence Scholarship</div>
                            <div class="award-org"><a href="https://www.google.com/">Google</a>, 2011</div>
                </div>
                <div class="award-item">
                    <div class="award-name">Top Ten Students</div>
<div class="award-org"><a href="https://www.scut.edu.cn/">South China University of Technology</a>, 2011</div>
                </div>
                <div class="award-item">
                    <div class="award-name">First Prize, 10th Guangdong Collegiate Programming Contest</div>
                    <div class="award-org">Guangdong, 2012</div>
                </div>
                <div class="award-item">
                    <div class="award-name">First Prize, 9th Guangdong Collegiate Programming Contest</div>
                    <div class="award-org">Guangdong, 2011</div>
                </div>
<div class="award-item">
                    <div class="award-name">Silver Medal, 35th <a href="https://icpc.global/">ACM-ICPC</a> Asia Regional (Harbin)</div>
                    <div class="award-org"><a href="https://www.acm.org/">ACM</a>, 2010</div>
                </div>
                <div class="award-item">
                    <div class="award-name">Silver Medal, 35th <a href="https://icpc.global/">ACM-ICPC</a> Asia Regional (Fuzhou)</div>
                    <div class="award-org"><a href="https://www.acm.org/">ACM</a>, 2010</div>
                </div>
            </div>
        </section>
    </div>
</body>
</html>
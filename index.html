<div>
    <table>
        <tbody>
            <tr>

                <td style="width:407px;height:472px"> &nbsp;
                    <div style="display:block;text-align:center;margin-right:auto;margin-left:auto"><a
                            href="https://sites.google.com/site/ygling2008/home/photo.png?attredirects=0"
                            imageanchor="1"><img border="0" height="400" src="https://ygling2008.github.io/photo.png"
                                width="353"></a></div>
                </td>

                <td align="left" valign="top">

                    <p style="line-height:1.4;margin-bottom:0em">&nbsp;</p>
                    <p style="line-height:1.4;margin-bottom:0em"><b>
                            <font color="#000000" size="5">Yonggen Ling &nbsp; </font>
                            <font color="#000000" face="arial, sans-serif" style="font-size:26.6667px">凌永根</font>
                        </b></p>

                    <p style="line-height:1.5;margin-bottom:0em">&nbsp;</p>
                    <p style="line-height:1.5;margin-bottom:0em"><b>
                            <font size="4">Ph.D. 2017</font>
                        </b></p>

                    <p style="line-height:1.5;margin-bottom:0em">
                        <a href="http://ri.ust.hk">Robotics Institute</a>, <a href="http://www.ece.ust.hk/">Department
                            of Electrical and Computer Engineering</a>, <a href="http://www.ust.hk/">
                            <font color="#224ba1">The Hong Kong University of Science and Technology</font>
                        </a> &nbsp;
                    </p>

                    <p style="line-height:1.5;margin-bottom:0em"><b>Email:</b> ylingaa AT connect.ust.hk</p>
                    <p style="line-height:1.5;margin-bottom:0em"><a
                            href="https://scholar.google.com/citations?user=P2HB2bsAAAAJ">Google Scholar</a></p>
                    <p style="line-height:1.5;margin-bottom:0em"><a href="https://github.com/ygling2008">Github</a></p>
                </td>
            </tr>
        </tbody>
    </table>
</div>
<div> </div>
<h2>
    <font color="#000000">Biography</font>
</h2>

I received my Ph.D. degree at the Robotics Institute (<b>RI</b>), Department of Electrical and Computer Engineering, The
Hong Kong University of Science and Technology (<b>HKUST</b>) in 2017. I was an ACM-ICPCer and had participted in lots of programming contests when I was an undergradudate. The learned
programming skills and algorithms related to computer science and maths built a strong foundation for my following
acadamic career. I started to work on image processing, video coding, and signal processing after joining the Multimedia
Technology Research Center (<b>MTrec</b>) supervised by Prof. Oscar C. Au (<b>IEEE Fellow</b>). I began to serve as an
intern for <a href="https://www.dji.com/cn">DJI</a> at the end of 2013, where I developed the vision module for UAVs.
During the internship, I was touched by the magic of computer vision and robotics. I decided to go further into these
topics in my acadamic career and joined the <a href="http://uav.ust.hk/">Prof. Shaojie Shen's UAV group</a>, where I
worked on visual odometry, mapping, 3D reconstruction, visual-inertial fusion, SLAM, and autonomous navigation. <br><br>

<b>
    <font color="#ff0000" size="4">[News] I am now a senior researcher scientist in Robotics X, Tencent. A few intern positions
        are available for talented Ph.D. and Master students. Please contact me via my email if you are interested and
        self-motivated to do cutting-edge work.</font>
</b>
<h2>
    <font color="#000000">Selected Publications</font>
</h2>
<div>
    <ul>
        <li>
            <p style="line-height:200%;text-align:justify">Boxiang Zhang, Zunran Wang, <b>Yonggen Ling</b>, Yuanyuan Guan, Shenghao Zhang, Wenhui Li, Lei Wei, Chunxu Zhang,<br>
                ShuffleTrans: Patch-wise weight shuffle for transparent object segmentation,<br>
                <i>Neural Networks</i> (<b>NN</b>), 2023. <br>
            </p>
        </li> 
        <li>
            <p style="line-height:200%;text-align:justify">Shifeng Lin, Zunran Wang, Shenghao Zhang, <b>Yonggen Ling</b>, Chenguang Yang,<br>
                Deep Fusion for Multi-Modal 6D Pose Estimation,<br>
                <i>IEEE Transactions on Automation Science and Engineering</i> (<b>TASE</b>), 2023. <br>
            </p>
        </li>        
        <li>
            <p style="line-height:200%;text-align:justify">Kaspar Althoefer*, <b>Yonggen Ling*</b>, Xinyuan Qian, Wang Wei Lee, Peng Qi and Wanlin Li,<br>
                A Miniaturised Camera-based Multi-Modal Tactile Sensor,<br>
                in <i>IEEE International Conference on Robotics and Automation</i> (<b>ICRA</b>), 2023.  (*equal contribution)
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify">Boxiang Zhang, Zunran Wang, <b>Yonggen Ling</b>, Yuanyuan
                Guan, Shenghao Zhang and Wenhui Li,<br>
                Mx2M: Masked Cross_Modality Modeling in Domain Adaptation for 3D semantic Segmentation,<br>
                in <i>AAAI Conference on Artificial Intelligent</i> (<b>AAAI</b>), 2023. <br>
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify">Haoxian Zhang* and <b>Yonggen Ling*&#9993</b>,<br>
                HVC-Net: Unifying Homography, Visibility, and Confidence Learning for Planar Object Tracking,<br>
                in <i>European Conference on Computer Vision</i> (<b>ECCV</b>), 2022.  (*equal contribution,
                &#9993corresponding author)
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify">Shifeng Lin, Zunran Wang, <b>Yonggen Ling</b>, Yidan Tao and
                Chenguang Yang,<br>
                E2EK: End-to-End Regression Network Based on Keypoint for 6D Pose Estimation,<br>
                <i>IEEE Robotics and Automation Letters</i> (<b>RAL</b>), 2022. <a
                    href="https://ieeexplore.ieee.org/document/9772945">[Paper]</a> <br>
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify">Hanzhong Liu, Bidan Huang, Qiang Li, Yu Zheng, <b>Yonggen
                    Ling</b>, Wang Wei Lee, Yi Liu, Ya-Yen Tsai and Chenguang Yang,<br>
                Multi-Finger Tactile Servoing for Grasping Adjustment under Partial Observation,<br>
                in <i>IEEE/RSJ International Conference on Intelligent Robots and Systems</i> (<b>IROS</b>), 2022.
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify">Yajing Chen, Fanzi Wu, Zeyu Wang, Yibing Song, <b>Yonggen
                    Ling</b> and Linchao Bao,<br>
                Self-Supervised Learning of Detailed 3D Face Reconstruction,<br>
                <i>IEEE Transactions on Image Processing</i> (<b>TIP</b>), 2020.
                <a href="https://arxiv.org/abs/1910.11791">[Paper]</a> <a
                    href="https://github.com/cyj907/unsupervised-detail-layer">[Code]</a><br>
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify"> <b>Yonggen Ling</b> and Shaojie Shen,<br>
                Real-time Dense Mapping for Online Processing and Navigation,<br>
                <i>Journal of Field Robotics</i> (<b>JFR</b>), 2019. <a
                    href="https://ygling2008.github.io/papers/JFR2019.pdf">[Paper]</a> <a
                    href="https://github.com/ygling2008/dense_mapping">[Code]</a> <br>

            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify"> Fanzi Wu, Linchao Bao, Yajing Chen, <b>Yonggen Ling</b>,
                Yibing Song, Songnan Li, King N. Ngan and Wei Liu,<br>
                MVF-Net: Multi-View 3D Face Morphable Model Regression,<br>
                in <i>Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2019. <a
                    href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_MVF-Net_Multi-View_3D_Face_Morphable_Model_Regression_CVPR_2019_paper.pdf">[Paper]</a>
                <br>
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify"><b>Yonggen Ling</b>, Linchao Bao, Zequn Jie, Fengming Zhu,
                Ziyang Li, Shanmin Tang, Yongsheng Liu, Wei Liu and Tong Zhang,<br>
                Modeling Varying Camera-IMU Time Offset in Optimization-Based Visual-Inertial Odometry,<br>
                in <i>European Conference on Computer Vision</i> (<b>ECCV</b>), 2018. <a
                    href="https://ygling2008.github.io/papers/ECCV2018.pdf">[Paper]</a> <br>
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify"><b>Yonggen Ling</b>, Kaixuan Wang and Shaojie Shen,<br>
                Probabilistic Dense Reconstruction from a Moving Camera,<br>
                in <i>IEEE/RSJ International Conference on Intelligent Robots and Systems</i> (<b>IROS</b>), 2018. <a
                    href="https://arxiv.org/abs/1903.10673">[Paper]</a><a
                    href="https://github.com/ygling2008/probabilistic_mapping">[Code]</a> <br>
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify"> Zequn Jie, Pengfei Wang, <b>Yonggen Ling</b>, Bo Zhao,
                Jiashi Feng and Wei Liu,<br>
                Left-Right Comparative Recurrent Model for Stereo Matching,<br>
                in <i>IEEE International Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>),
                <b>Oral</b>, 2018. <a href="https://arxiv.org/abs/1804.00796">[Paper]</a> <br>
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify"> <b>Yonggen Ling</b>, Manohar Kuse and Shaojie Shen,<br>
                Edge Alignment-Based Visual-Inertial Fusion for Tracking of Aggressive Motions,<br>
                <i>Autonomous Robots</i> (<b>AURO</b>), 2017. <a
                    href="https://ygling2008.github.io/papers/AURO2017.pdf">[Paper]</a><a
                    href="https://github.com/ygling2008/direct_edge_imu">[Code]</a><br>
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify"> <b>Yonggen Ling</b> and Shaojie Shen,<br>
                Building Maps for Autonomous Navigation Using Sparse Visual SLAM Features,<br>
                in <i>IEEE/RSJ International Conference on Intelligent Robots and Systems</i> (<b>IROS</b>), 2017. <a
                    href="https://ygling2008.github.io/papers/IROS2017.pdf">[Paper]</a><a
                    href="https://github.com/ygling2008/lightweight_mapping">[Code]</a> <br>
            </p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify"> <b>Yonggen Ling</b> and Shaojie Shen,<br>
                High-Precision Online Markerless Stereo Extrinsic Calibration,<br>
                in <i>IEEE/RSJ International Conference on Intelligent Robots and Systems</i> (<b>IROS</b>), 2016. <a
                    href="https://arxiv.org/abs/1903.10705">[Paper]</a></p>
        </li>
        <li>
            <p style="line-height:200%;text-align:justify"> <b>Yonggen Ling</b>, Tianbo Liu and Shaojie Shen,<br>
                Aggressive Quadrotor Flight Using Dense Visual-Inertial Fusion,<br>
                in <i>IEEE International Conference on Robotics and Automation</i> (<b>ICRA</b>), 2016. <a
                    href="https://ygling2008.github.io/papers/ICRA2016.pdf">[Paper]</a><a
                    href="https://github.com/ygling2008/direct_edge_imu">[Code]</a><br>
            </p>
        </li>

    </ul>
    <div>

    </div>
    <h2>
        <font color="#000000">Work Experience</font>
    </h2>
    <div>
    </div>
    <ul>
        <li>
            <p style="margin-bottom:0.3em"><b>Research Assistant</b>, HKUST, Sep. 2016 - Aug. 2017</p>
        </li>
        <li>
            <p style="margin-bottom:0.3em"><b>Intern in Vision Lab</b>, Dajiang Innovation, Jan. 2014 - Dec. 2014<br>
            </p>
        </li>
        <li>
            <p style="margin-bottom:0.3em"><b>Intern in Multimedia Lab</b>, Shenzhen Institute of Advanced Technology,
                Chinese Academy of Sciences, Feb. 2012 - Sep. 2012<br>
                Mentors: Prof. Shifeng Chen &amp; Prof. Wei Zhang</p>
        </li>
    </ul>
    <div>

    </div>
    <h2>
        <font color="#000000">Scholarships &amp; Awards </font>
    </h2>
    <div>
    </div>
    <ul>
        <li>
            <p style="margin-bottom:0.3em"><b>Research Travel Grant</b>, HKUST, 2014, 2015, 2016<br>
            </p>
        </li>
        <li>
            <p style="margin-bottom:0.3em"><b>Postgraduate Scholarship</b>, HKUST, Sep. 2012 - Aug. 2016<br>
            </p>
        </li>
        <li>
            <p style="margin-bottom:0.3em"><b>National Scholarship</b>, China, 2009, 2010, 2011<br>
            </p>
        </li>
        <li>
            <p style="margin-bottom:0.3em"><b>Google Excellence Scholarship</b>, Google, 2011<br>
            </p>
        </li>
        <li>
            <p style="margin-bottom:0.3em"><b>Top Ten Students in South China University of Technology</b>, SCUT,
                2011<br>
            </p>
        <li>
            <p style="margin-bottom:0.3em"><b>First Prize for 10th Guangdong Collegiate Programming Contest, Guangdong,
                </b>2012<br>
            </p>
        </li>
        <li>
            <p style="margin-bottom:0.3em"><b>First Prize for 9th Guangdong Collegiate Programming Contest, Guangdong,
                </b>2011<br>
            </p>
        </li>
        <li>
            <p style="margin-bottom:0.3em"><b>Silver Medal for 35th ACM International Collegiate Programming Contest,
                    Asia Regional, Harbin Site, ACM, </b>2010 <br>
            </p>
        </li>
        <li>
            <p style="margin-bottom:0.3em"><b>Silver Medal for 35th ACM International Collegiate Programming Contest,
                    Asia Regional, Fuzhou Site, ACM, </b>2010<br>
            </p>
        </li>
    </ul>
    <div>
    </ul>